# .github/workflows/spanish-learning-automation.yml
name: ìŠ¤í˜ì¸ì–´ í•™ìŠµ ìë£Œ ìë™ ìˆ˜ì§‘

on:
  schedule:
    # ë§¤ì¼ UTC 23:00 (í•œêµ­ì‹œê°„ ì˜¤ì „ 8ì‹œ)ì— ì‹¤í–‰
    - cron: "0 23 * * 1-5" # í‰ì¼ë§Œ ì‹¤í–‰
  workflow_dispatch: # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

env:
  NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
  NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}

jobs:
  collect-learning-materials:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 feedparser python-dateutil lxml

      - name: Calculate learning phase and schedule
        id: phase
        run: |
          python3 << 'EOF'
          import os
          from datetime import datetime, timedelta

          # í•™ìŠµ ì‹œì‘ì¼ (2025-07-01)
          start_date = datetime(2025, 7, 1)
          current_date = datetime.now()

          # ì£¼ì°¨ ê³„ì‚°
          week_num = (current_date - start_date).days // 7 + 1
          weekday = current_date.weekday()  # 0=ì›”ìš”ì¼

          # ë…í•´ ì†ŒìŠ¤ ê²°ì •
          if week_num <= 2:
              reading_source = "20minutos"
              reading_url = "https://www.20minutos.es/"
              reading_difficulty = "B2"
          elif week_num <= 4:
              reading_source = "El PaÃ­s ë‹¨ì‹ "
              reading_url = "https://elpais.com/"
              reading_difficulty = "B2"
          else:
              reading_source = "El PaÃ­s ì‚¬ì„¤"
              reading_url = "https://elpais.com/opinion/"
              reading_difficulty = "C1"
              
          # íŒŸìºìŠ¤íŠ¸ ì¼ì • (RSS í”¼ë“œì™€ Apple Podcasts ë§í¬)
          podcast_schedule = {
              0: {
                  "name": "Hoy Hablamos",
                  "rss": "https://feeds.feedburner.com/hoyhablamos",
                  "apple_base": "https://podcasts.apple.com/kr/podcast/hoy-hablamos-podcast-diario-para-aprender-espaÃ±ol-learn/id1201483158",
                  "region": "ìŠ¤í˜ì¸",
                  "backup_url": "https://www.hoyhablamos.com/"
              },
              1: {
                  "name": "Radio Ambulante", 
                  "rss": "https://feeds.npr.org/510311/podcast.xml",
                  "apple_base": "https://podcasts.apple.com/kr/podcast/radio-ambulante/id527614348",
                  "region": "ì¤‘ë‚¨ë¯¸",
                  "backup_url": "https://radioambulante.org/"
              },
              2: {
                  "name": "Advanced Spanish",
                  "rss": "https://feeds.buzzsprout.com/1829091.rss", 
                  "apple_base": "https://podcasts.apple.com/kr/podcast/advanced-spanish-podcast-espaÃ±ol-avanzado/id1632291264",
                  "region": "ìŠ¤í˜ì¸",
                  "backup_url": "https://www.spanishlanguagecoach.com/podcast/"
              },
              3: {
                  "name": "Radio Ambulante",
                  "rss": "https://feeds.npr.org/510311/podcast.xml",
                  "apple_base": "https://podcasts.apple.com/kr/podcast/radio-ambulante/id527614348", 
                  "region": "ì¤‘ë‚¨ë¯¸",
                  "backup_url": "https://radioambulante.org/"
              },
              4: {
                  "name": "DELE Podcast",
                  "rss": "https://anchor.fm/s/f4f4a4f0/podcast/rss",
                  "apple_base": "https://podcasts.apple.com/us/podcast/examen-dele/id1705001626",
                  "region": "ìŠ¤í˜ì¸", 
                  "backup_url": "https://anchor.fm/examen-dele"
              }
          }

          podcast_info = podcast_schedule.get(weekday, podcast_schedule[0])

          # GitHub Actions í™˜ê²½ë³€ìˆ˜ë¡œ ì¶œë ¥
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"week_num={week_num}\n")
              f.write(f"reading_source={reading_source}\n")
              f.write(f"reading_url={reading_url}\n")
              f.write(f"reading_difficulty={reading_difficulty}\n")
              f.write(f"podcast_name={podcast_info['name']}\n")
              f.write(f"podcast_rss={podcast_info['rss']}\n")
              f.write(f"podcast_apple_base={podcast_info['apple_base']}\n")
              f.write(f"podcast_region={podcast_info['region']}\n")
              f.write(f"podcast_backup={podcast_info['backup_url']}\n")
              f.write(f"date={current_date.strftime('%Y-%m-%d')}\n")
              f.write(f"weekday_name={['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'][weekday]}\n")
          EOF

      - name: Collect articles and podcast episodes with detailed info
        id: materials
        run: |
          python3 << 'EOF'
          import os
          import requests
          import feedparser
          from datetime import datetime
          import re
          from bs4 import BeautifulSoup
          from urllib.parse import urljoin

          def extract_category_from_summary(summary):
              keywords = {
                  'ì •ì¹˜': ['gobierno', 'polÃ­tica', 'elecciones', 'parlamento', 'ministro', 'rey'],
                  'ê²½ì œ': ['economÃ­a', 'banco', 'euro', 'empleo', 'crisis', 'mercado', 'dinero', 'trabajo'],
                  'ì‚¬íšŒ': ['sociedad', 'educaciÃ³n', 'sanidad', 'vivienda', 'familia', 'salud'],
                  'ìŠ¤í¬ì¸ ': ['fÃºtbol', 'Real Madrid', 'Barcelona', 'Liga', 'deporte', 'partido'],
                  'ê¸°ìˆ ': ['tecnologÃ­a', 'internet', 'mÃ³vil', 'digital', 'app', 'inteligencia'],
                  'ë¬¸í™”': ['cultura', 'arte', 'mÃºsica', 'teatro', 'festival', 'libro']
              }
              
              summary_lower = summary.lower()
              for category, words in keywords.items():
                  if any(word in summary_lower for word in words):
                      return category
              return 'ì¼ë°˜'

          def extract_episode_number(title):
              patterns = [
                  r'Ep\.?\s*(\d+)',
                  r'Episode\s*(\d+)',
                  r'#(\d+)',
                  r'(\d{3,4})'
              ]
              
              for pattern in patterns:
                  match = re.search(pattern, title, re.IGNORECASE)
                  if match:
                      return match.group(1)
              return None

          def extract_duration_from_feed(entry):
              if hasattr(entry, 'itunes_duration'):
                  return entry.itunes_duration
              
              summary = entry.get('summary', '') + entry.get('description', '')
              duration_patterns = [
                  r'(\d+)\s*min',
                  r'(\d+)\s*ë¶„',
                  r'(\d+):(\d+)',
                  r'Duration:\s*(\d+)'
              ]
              
              for pattern in duration_patterns:
                  match = re.search(pattern, summary)
                  if match:
                      if ':' in pattern:
                          return f"{match.group(1)}:{match.group(2)}"
                      else:
                          return f"{match.group(1)}ë¶„"
              
              return "15-25ë¶„"

          def extract_topic_keywords(title, summary=""):
              content = (title + " " + summary).lower()
              
              topic_keywords = {
                  'ë¬¸ë²•': ['gramÃ¡tica', 'verbos', 'subjuntivo', 'pretÃ©rito', 'sintaxis'],
                  'ë¬¸í™”': ['cultura', 'tradiciÃ³n', 'costumbres', 'historia', 'arte'],
                  'ìš”ë¦¬': ['cocina', 'comida', 'receta', 'gastronomÃ­a', 'plato'],
                  'ì—¬í–‰': ['viajes', 'turismo', 'ciudades', 'lugares', 'destinos'],
                  'ì§ì—…': ['trabajo', 'empleo', 'profesiÃ³n', 'carrera', 'oficina'],
                  'ê°€ì¡±': ['familia', 'padres', 'hijos', 'matrimonio', 'casa'],
                  'ê¸°ìˆ ': ['tecnologÃ­a', 'internet', 'mÃ³viles', 'digital', 'aplicaciones'],
                  'ì •ì¹˜': ['polÃ­tica', 'gobierno', 'elecciones', 'democracia'],
                  'ê²½ì œ': ['economÃ­a', 'dinero', 'banco', 'trabajo', 'crisis', 'preferentes', 'ahorros'],
                  'ì‚¬íšŒ': ['sociedad', 'gente', 'problemas', 'cambios', 'vida'],
                  'ê±´ê°•': ['salud', 'medicina', 'hospital', 'enfermedad', 'mÃ©dico'],
                  'êµìœ¡': ['educaciÃ³n', 'estudiantes', 'universidad', 'aprender']
              }
              
              for topic, keywords in topic_keywords.items():
                  if any(keyword in content for keyword in keywords):
                      return topic
              return 'ì¼ë°˜ ì£¼ì œ'

          def get_key_expressions(title, summary=""):
              content = title + " " + summary
              
              expression_patterns = [
                  r"'([^']+)'",
                  r'"([^"]+)"',
                  r'\b(caer en la trampa|perder los ahorros|hacer caso|darse cuenta|tener en cuenta|por si acaso|de vez en cuando)\b'
              ]
              
              expressions = []
              for pattern in expression_patterns:
                  matches = re.findall(pattern, content, re.IGNORECASE)
                  expressions.extend(matches)
              
              if 'preferentes' in content.lower() or 'ahorros' in content.lower():
                  expressions.extend(['caer en la trampa', 'perder los ahorros', 'productos financieros'])
              
              return expressions[:3]

          def create_detailed_memo(content_type, data, weekday_name):
              if content_type == "article":
                  category = data.get('category', 'ì¼ë°˜')
                  preview = data.get('preview', '')[:100] + '...' if data.get('preview') else ''
                  # ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                  preview = preview.replace('"', '\\"').replace("'", "\\'")
                  
                  return (f"ğŸ“° {category} ë¶„ì•¼ ê¸°ì‚¬ "
                         f"ğŸ“… ë°œí–‰: {data.get('published', 'ì˜¤ëŠ˜')} "
                         f"ğŸ¯ í•™ìŠµëª©í‘œ: 15ë¶„ ë…í•´, ì–´íœ˜ 5ê°œ ì •ë¦¬ "
                         f"ğŸ’¡ ë¯¸ë¦¬ë³´ê¸°: {preview} "
                         f"ğŸ“ ê¶Œì¥: ëª¨ë¥´ëŠ” ë‹¨ì–´ëŠ” ë…¸íŠ¸ì— ì •ë¦¬í•˜ë©° ì½ê¸°")

              elif content_type == "podcast":
                  podcast_name = data.get('podcast_name', '')
                  duration = data.get('duration', '15-25ë¶„')
                  topic = data.get('topic', 'ì¼ë°˜ ì£¼ì œ')
                  expressions = data.get('expressions', [])
                  episode_num = data.get('episode_number', '')
                  
                  expressions_text = ""
                  if expressions:
                      # ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                      clean_expressions = [expr.replace('"', '\\"').replace("'", "\\'") for expr in expressions[:2]]
                      expr_list = "', '".join(clean_expressions)
                      expressions_text = f"ğŸ’¡ í•µì‹¬ í‘œí˜„: '{expr_list}' "
                  
                  return (f"ğŸ§ {podcast_name} Ep.{episode_num} - {weekday_name} ìŠ¤í˜ì¸ íŒŸìºìŠ¤íŠ¸ "
                         f"â±ï¸ ì¬ìƒì‹œê°„: {duration} (ì „ì²´ 25ë¶„ ì²­ì·¨ ê³„íš) "
                         f"ğŸ¯ í•™ìŠµëª©í‘œ: ê¸ˆìœµ ì–´íœ˜ 5ê°œ ì •ë¦¬ "
                         f"ğŸŒ ì£¼ì œ: {topic} "
                         f"{expressions_text}"
                         f"ğŸ“ ê¶Œì¥: í•µì‹¬ ì–´íœ˜ì— ì§‘ì¤‘í•˜ì—¬ ì²­ì·¨")

          # ê¸°ì‚¬ ìˆ˜ì§‘
          reading_source = "${{ steps.phase.outputs.reading_source }}"
          article_data = None

          try:
              if reading_source == "20minutos":
                  feed_url = "https://www.20minutos.es/rss/"
              elif "El PaÃ­s" in reading_source:
                  if "ì‚¬ì„¤" in reading_source:
                      feed_url = "https://feeds.elpais.com/mrss-s/pages/ep/site/elpais.com/section/opinion"
                  else:
                      feed_url = "https://feeds.elpais.com/mrss-s/pages/ep/site/elpais.com/portada"
              
              feed = feedparser.parse(feed_url)
              if feed.entries:
                  latest = feed.entries[0]
                  summary = latest.get('summary', '')
                  # ì œëª© ì •ë¦¬ (escape sequence ì œê±°)
                  clean_title = latest.title.replace('&quot;', '"').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
                  article_data = {
                      'title': clean_title,
                      'url': latest.link,
                      'published': latest.get('published', ''),
                      'category': extract_category_from_summary(summary),
                      'preview': summary
                  }
          except Exception as e:
              print(f"ê¸°ì‚¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

          # íŒŸìºìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ìˆ˜ì§‘
          podcast_rss = "${{ steps.phase.outputs.podcast_rss }}"
          podcast_name = "${{ steps.phase.outputs.podcast_name }}"
          weekday_name = "${{ steps.phase.outputs.weekday_name }}"
          podcast_data = None

          try:
              feed = feedparser.parse(podcast_rss)
              if feed.entries:
                  latest = feed.entries[0]
                  episode_number = extract_episode_number(latest.title)
                  duration = extract_duration_from_feed(latest)
                  topic = extract_topic_keywords(latest.title, latest.get('summary', ''))
                  expressions = get_key_expressions(latest.title, latest.get('summary', ''))
                  
                  apple_base = "${{ steps.phase.outputs.podcast_apple_base }}"
                  episode_link = latest.link
                  
                  # Apple Podcasts ë§í¬ ìƒì„± ê°œì„ 
                  if 'npr.org' in episode_link or 'radioambulante' in episode_link:
                      # Radio Ambulanteì˜ ê²½ìš° ê¸°ë³¸ ë§í¬ ì‚¬ìš©
                      apple_episode_link = apple_base
                  else:
                      # ë‹¤ë¥¸ íŒŸìºìŠ¤íŠ¸ëŠ” ì—í”¼ì†Œë“œ ID ì¶”ì¶œ ì‹œë„
                      episode_id_match = re.search(r'/(\d+)', episode_link)
                      if episode_id_match:
                          apple_episode_link = f"{apple_base}?i={episode_id_match.group(1)}"
                      else:
                          apple_episode_link = apple_base
                  
                  # ì œëª© ì •ë¦¬ (escape sequence ì œê±°)
                  clean_title = latest.title.replace('&quot;', '"').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
                  
                  podcast_data = {
                      'podcast_name': podcast_name,
                      'title': clean_title,
                      'url': apple_episode_link,
                      'original_url': episode_link,
                      'duration': duration,
                      'topic': topic,
                      'expressions': expressions,
                      'episode_number': episode_number or 'Latest',
                      'published': latest.get('published', ''),
                      'region': "${{ steps.phase.outputs.podcast_region }}"
                  }
          except Exception as e:
              print(f"íŒŸìºìŠ¤íŠ¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
              podcast_data = {
                  'podcast_name': podcast_name,
                  'title': f"{podcast_name} - ìµœì‹  ì—í”¼ì†Œë“œ",
                  'url': "${{ steps.phase.outputs.podcast_apple_base }}",
                  'duration': "15-25ë¶„",
                  'topic': "ì¼ë°˜ ì£¼ì œ",
                  'expressions': [],
                  'episode_number': 'Latest',
                  'region': "${{ steps.phase.outputs.podcast_region }}"
              }

          # ê²°ê³¼ ì¶œë ¥
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              if article_data:
                  # ë”°ì˜´í‘œì™€ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                  article_title_clean = article_data['title'].replace('\n', ' ').replace('\r', ' ').replace('"', '\\"').replace("'", "\\'")
                  article_memo_clean = create_detailed_memo('article', article_data, weekday_name)
                  f.write(f"article_title={article_title_clean}\n")
                  f.write(f"article_url={article_data['url']}\n")
                  f.write(f"article_memo={article_memo_clean}\n")
              
              if podcast_data:
                  # ë”°ì˜´í‘œì™€ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                  podcast_title_clean = podcast_data['title'].replace('\n', ' ').replace('\r', ' ').replace('"', '\\"').replace("'", "\\'")
                  podcast_memo_clean = create_detailed_memo('podcast', podcast_data, weekday_name)
                  f.write(f"podcast_title={podcast_title_clean}\n")
                  f.write(f"podcast_url={podcast_data['url']}\n")
                  f.write(f"podcast_memo={podcast_memo_clean}\n")
                  f.write(f"episode_number={podcast_data['episode_number']}\n")
          EOF

      - name: Add materials to Notion with detailed information
        run: |
          python3 << 'EOF'
          import os
          import requests
          import json
          from datetime import datetime

          notion_token = os.environ['NOTION_TOKEN']
          database_id = os.environ['NOTION_DATABASE_ID']

          headers = {
              "Authorization": f"Bearer {notion_token}",
              "Notion-Version": "2022-06-28", 
              "Content-Type": "application/json"
          }

          today = "${{ steps.phase.outputs.date }}"

          # ë…í•´ ìë£Œ ì¶”ê°€
          article_title = "${{ steps.materials.outputs.article_title }}"
          article_url = "${{ steps.materials.outputs.article_url }}"
          article_memo = "${{ steps.materials.outputs.article_memo }}"

          if article_title and article_url:
              reading_payload = {
                  "parent": {"database_id": database_id},
                  "properties": {
                      "ë‚´ìš©": {"title": [{"text": {"content": f"[{today}] {article_title}"}}]},
                      "URL": {"url": article_url},
                      "ë‚ ì§œ": {"date": {"start": today}},
                      "ì§€ì—­": {"select": {"name": "ìŠ¤í˜ì¸"}},
                      "ë‚œì´ë„": {"select": {"name": "${{ steps.phase.outputs.reading_difficulty }}"}},
                      "ìë£Œ ìœ í˜•": {"select": {"name": "ê¸°ì‚¬/ë‰´ìŠ¤"}},
                      "í•™ìŠµ ì˜ì—­": {"select": {"name": "ë…í•´"}},
                      "ë©”ëª¨": {"rich_text": [{"text": {"content": article_memo}}]}
                  }
              }
              
              try:
                  response = requests.post(
                      "https://api.notion.com/v1/pages",
                      headers=headers,
                      json=reading_payload
                  )
                  if response.status_code == 200:
                      print(f"âœ… ë…í•´ ìë£Œ ì¶”ê°€ ì„±ê³µ: {article_title}")
                  else:
                      print(f"âŒ ë…í•´ ìë£Œ ì¶”ê°€ ì‹¤íŒ¨: {response.text}")
              except Exception as e:
                  print(f"ë…í•´ ìë£Œ ì „ì†¡ ì˜¤ë¥˜: {e}")

          # ì²­í•´ ìë£Œ ì¶”ê°€
          podcast_title = "${{ steps.materials.outputs.podcast_title }}"
          podcast_url = "${{ steps.materials.outputs.podcast_url }}"
          podcast_memo = "${{ steps.materials.outputs.podcast_memo }}"
          episode_number = "${{ steps.materials.outputs.episode_number }}"

          display_title = f"${{ steps.phase.outputs.podcast_name }} Ep.{episode_number}"

          podcast_payload = {
              "parent": {"database_id": database_id},
              "properties": {
                  "ë‚´ìš©": {"title": [{"text": {"content": f"[{today}] {display_title}"}}]},
                  "URL": {"url": podcast_url},
                  "ë‚ ì§œ": {"date": {"start": today}},
                  "ì§€ì—­": {"select": {"name": "${{ steps.phase.outputs.podcast_region }}"}},
                  "ë‚œì´ë„": {"select": {"name": "C1"}},
                  "ìë£Œ ìœ í˜•": {"select": {"name": "íŒŸìºìŠ¤íŠ¸"}},
                  "í•™ìŠµ ì˜ì—­": {"select": {"name": "ì²­í•´"}},
                  "ë©”ëª¨": {"rich_text": [{"text": {"content": podcast_memo}}]}
              }
          }

          try:
              response = requests.post(
                  "https://api.notion.com/v1/pages",
                  headers=headers,
                  json=podcast_payload
              )
              if response.status_code == 200:
                  print(f"âœ… ì²­í•´ ìë£Œ ì¶”ê°€ ì„±ê³µ: {display_title}")
              else:
                  print(f"âŒ ì²­í•´ ìë£Œ ì¶”ê°€ ì‹¤íŒ¨: {response.text}")
          except Exception as e:
              print(f"ì²­í•´ ìë£Œ ì „ì†¡ ì˜¤ë¥˜: {e}")
          EOF

      - name: Send detailed notification
        if: success()
        run: |
          echo "ğŸ‰ ${{ steps.phase.outputs.date }} (${{ steps.phase.outputs.weekday_name }}) ìŠ¤í˜ì¸ì–´ í•™ìŠµ ìë£Œ ìë™ ìˆ˜ì§‘ ì™„ë£Œ!"
          echo ""
          echo "ğŸ“– ë…í•´ ìë£Œ:"
          echo "   ì œëª©: ${{ steps.materials.outputs.article_title }}"
          echo "   ì¶œì²˜: ${{ steps.phase.outputs.reading_source }}"
          echo "   ë‚œì´ë„: ${{ steps.phase.outputs.reading_difficulty }}"
          echo ""
          echo "ğŸ§ ì²­í•´ ìë£Œ:"
          echo "   ì œëª©: ${{ steps.phase.outputs.podcast_name }} Ep.${{ steps.materials.outputs.episode_number }}"
          echo "   ì§€ì—­: ${{ steps.phase.outputs.podcast_region }}"
          echo "   ë§í¬: Apple Podcasts ì•±ì—ì„œ ì¬ìƒ ê°€ëŠ¥"
          echo ""
          echo "ğŸ“… í•™ìŠµ ì£¼ì°¨: ${{ steps.phase.outputs.week_num }}ì£¼ì°¨"
          echo "ğŸ’¡ íŒ: íŒŸìºìŠ¤íŠ¸ëŠ” Apple Podcasts ì•±ì„ í†µí•´ ì ‘ì†í•˜ì‹œë©´ ì›í™œí•˜ê²Œ ì¬ìƒë©ë‹ˆë‹¤!"
