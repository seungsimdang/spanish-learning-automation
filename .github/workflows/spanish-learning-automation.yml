# .github/workflows/spanish-learning-automation.yml
name: ìŠ¤í˜ì¸ì–´ í•™ìŠµ ìë£Œ ìë™ ìˆ˜ì§‘

on:
  schedule:
    # ë§¤ì¼ UTC 23:00 (í•œêµ­ì‹œê°„ ì˜¤ì „ 8ì‹œ)ì— ì‹¤í–‰
    - cron: "0 23 * * 1-5" # í‰ì¼ë§Œ ì‹¤í–‰
  workflow_dispatch: # ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

env:
  NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
  NOTION_DATABASE_ID: ${{ secrets.NOTION_DATABASE_ID }}

jobs:
  collect-learning-materials:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 feedparser python-dateutil lxml

      - name: Calculate learning phase and schedule
        id: phase
        run: |
          python3 << 'EOF'
          import os
          from datetime import datetime, timedelta

          # í•™ìŠµ ì‹œì‘ì¼ (2025-07-01)
          start_date = datetime(2025, 7, 1)
          current_date = datetime.now()

          # ì£¼ì°¨ ê³„ì‚°
          week_num = (current_date - start_date).days // 7 + 1
          weekday = current_date.weekday()  # 0=ì›”ìš”ì¼

          # ë…í•´ ì†ŒìŠ¤ ê²°ì •
          if week_num <= 2:
              reading_source = "20minutos"
              reading_url = "https://www.20minutos.es/"
              reading_difficulty = "B2"
          elif week_num <= 4:
              reading_source = "El PaÃ­s ë‹¨ì‹ "
              reading_url = "https://elpais.com/"
              reading_difficulty = "B2"
          else:
              reading_source = "El PaÃ­s ì‚¬ì„¤"
              reading_url = "https://elpais.com/opinion/"
              reading_difficulty = "C1"
              
          # íŒŸìºìŠ¤íŠ¸ ì¼ì • (RSS í”¼ë“œì™€ Apple Podcasts ë§í¬)
          podcast_schedule = {
              0: {
                  "name": "Hoy Hablamos",
                  "rss": "https://feeds.feedburner.com/hoyhablamos",
                  "apple_base": "https://podcasts.apple.com/kr/podcast/hoy-hablamos-podcast-diario-para-aprender-espaÃ±ol-learn/id1201483158",
                  "region": "ìŠ¤í˜ì¸",
                  "backup_url": "https://www.hoyhablamos.com/"
              },
              1: {
                  "name": "Radio Ambulante", 
                  "rss": "https://feeds.npr.org/510311/podcast.xml",
                  "apple_base": "https://podcasts.apple.com/kr/podcast/radio-ambulante/id527614348",
                  "region": "ì¤‘ë‚¨ë¯¸",
                  "backup_url": "https://radioambulante.org/"
              },
              2: {
                  "name": "Advanced Spanish",
                  "rss": "https://feeds.buzzsprout.com/1829091.rss", 
                  "apple_base": "https://podcasts.apple.com/kr/podcast/advanced-spanish-podcast-espaÃ±ol-avanzado/id1632291264",
                  "region": "ìŠ¤í˜ì¸",
                  "backup_url": "https://www.spanishlanguagecoach.com/podcast/"
              },
              3: {
                  "name": "Radio Ambulante",
                  "rss": "https://feeds.npr.org/510311/podcast.xml",
                  "apple_base": "https://podcasts.apple.com/kr/podcast/radio-ambulante/id527614348", 
                  "region": "ì¤‘ë‚¨ë¯¸",
                  "backup_url": "https://radioambulante.org/"
              },
              4: {
                  "name": "DELE Podcast",
                  "rss": "https://anchor.fm/s/f4f4a4f0/podcast/rss",
                  "apple_base": "https://podcasts.apple.com/us/podcast/examen-dele/id1705001626",
                  "region": "ìŠ¤í˜ì¸", 
                  "backup_url": "https://anchor.fm/examen-dele"
              }
          }

          podcast_info = podcast_schedule.get(weekday, podcast_schedule[0])

          # GitHub Actions í™˜ê²½ë³€ìˆ˜ë¡œ ì¶œë ¥
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"week_num={week_num}\n")
              f.write(f"reading_source={reading_source}\n")
              f.write(f"reading_url={reading_url}\n")
              f.write(f"reading_difficulty={reading_difficulty}\n")
              f.write(f"podcast_name={podcast_info['name']}\n")
              f.write(f"podcast_rss={podcast_info['rss']}\n")
              f.write(f"podcast_apple_base={podcast_info['apple_base']}\n")
              f.write(f"podcast_region={podcast_info['region']}\n")
              f.write(f"podcast_backup={podcast_info['backup_url']}\n")
              f.write(f"date={current_date.strftime('%Y-%m-%d')}\n")
              f.write(f"weekday_name={['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼'][weekday]}\n")
          EOF

      - name: Collect articles and podcast episodes with detailed info
        id: materials
        run: |
          python3 << 'EOF'
          import os
          import requests
          import feedparser
          from datetime import datetime
          import re
          from bs4 import BeautifulSoup
          from urllib.parse import urljoin

          def extract_category_from_summary(summary):
              keywords = {
                  'ì •ì¹˜': ['gobierno', 'polÃ­tica', 'elecciones', 'parlamento', 'ministro', 'rey'],
                  'ê²½ì œ': ['economÃ­a', 'banco', 'euro', 'empleo', 'crisis', 'mercado', 'dinero', 'trabajo'],
                  'ì‚¬íšŒ': ['sociedad', 'educaciÃ³n', 'sanidad', 'vivienda', 'familia', 'salud'],
                  'ìŠ¤í¬ì¸ ': ['fÃºtbol', 'Real Madrid', 'Barcelona', 'Liga', 'deporte', 'partido'],
                  'ê¸°ìˆ ': ['tecnologÃ­a', 'internet', 'mÃ³vil', 'digital', 'app', 'inteligencia'],
                  'ë¬¸í™”': ['cultura', 'arte', 'mÃºsica', 'teatro', 'festival', 'libro']
              }
              
              summary_lower = summary.lower()
              for category, words in keywords.items():
                  if any(word in summary_lower for word in words):
                      return category
              return 'ì¼ë°˜'

          def extract_episode_number(title):
              patterns = [
                  r'Ep\.?\s*(\d+)',
                  r'Episode\s*(\d+)',
                  r'#(\d+)',
                  r'(\d{3,4})'
              ]
              
              for pattern in patterns:
                  match = re.search(pattern, title, re.IGNORECASE)
                  if match:
                      return match.group(1)
              return None

          def extract_duration_from_feed(entry):
              # iTunes ë“€ë ˆì´ì…˜ ë¨¼ì € í™•ì¸
              if hasattr(entry, 'itunes_duration'):
                  duration = entry.itunes_duration
                  # ì´ˆ ë‹¨ìœ„ì¸ ê²½ìš° ë¶„:ì´ˆë¡œ ë³€í™˜
                  if duration.isdigit():
                      total_seconds = int(duration)
                      minutes = total_seconds // 60
                      seconds = total_seconds % 60
                      return f"{minutes}:{seconds:02d}"
                  return duration
              
              # ìš”ì•½ì—ì„œ ì¬ìƒì‹œê°„ ì¶”ì¶œ ì‹œë„
              summary = entry.get('summary', '') + entry.get('description', '')
              duration_patterns = [
                  r'(\d+)\s*min',
                  r'(\d+)\s*ë¶„',
                  r'(\d+):(\d+)',
                  r'Duration:\s*(\d+)'
              ]
              
              for pattern in duration_patterns:
                  match = re.search(pattern, summary)
                  if match:
                      if ':' in pattern:
                          return f"{match.group(1)}:{match.group(2)}"
                      else:
                          return f"{match.group(1)}ë¶„"
              
              return "15-25ë¶„"

          def extract_topic_keywords(title, summary=""):
              content = (title + " " + summary).lower()
              
              topic_keywords = {
                  'ë¬¸ë²•': ['gramÃ¡tica', 'verbos', 'subjuntivo', 'pretÃ©rito', 'sintaxis'],
                  'ë¬¸í™”': ['cultura', 'tradiciÃ³n', 'costumbres', 'historia', 'arte'],
                  'ìš”ë¦¬': ['cocina', 'comida', 'receta', 'gastronomÃ­a', 'plato'],
                  'ì—¬í–‰': ['viajes', 'turismo', 'ciudades', 'lugares', 'destinos'],
                  'ì§ì—…': ['trabajo', 'empleo', 'profesiÃ³n', 'carrera', 'oficina'],
                  'ê°€ì¡±': ['familia', 'padres', 'hijos', 'matrimonio', 'casa'],
                  'ê¸°ìˆ ': ['tecnologÃ­a', 'internet', 'mÃ³viles', 'digital', 'aplicaciones'],
                  'ì •ì¹˜': ['polÃ­tica', 'gobierno', 'elecciones', 'democracia'],
                  'ê²½ì œ': ['economÃ­a', 'dinero', 'banco', 'trabajo', 'crisis', 'preferentes', 'ahorros'],
                  'ì‚¬íšŒ': ['sociedad', 'gente', 'problemas', 'cambios', 'vida'],
                  'ê±´ê°•': ['salud', 'medicina', 'hospital', 'enfermedad', 'mÃ©dico'],
                  'êµìœ¡': ['educaciÃ³n', 'estudiantes', 'universidad', 'aprender']
              }
              
              for topic, keywords in topic_keywords.items():
                  if any(keyword in content for keyword in keywords):
                      return topic
              return 'ì¼ë°˜ ì£¼ì œ'

          def get_key_expressions(title, summary=""):
              content = title + " " + summary
              
              # ìŠ¤í˜ì¸ì–´ í•µì‹¬ í‘œí˜„ê³¼ í•œêµ­ì–´ ëœ» ì‚¬ì „
              expression_dict = {
                  # ì¼ë°˜ì ì¸ ê´€ìš© í‘œí˜„
                  'caer en la trampa': 'í•¨ì •ì— ë¹ ì§€ë‹¤',
                  'perder los ahorros': 'ì €ì¶•ì„ ìƒë‹¤',
                  'hacer caso': 'ì‹ ê²½ ì“°ë‹¤, ì£¼ì˜ë¥¼ ê¸°ìš¸ì´ë‹¤',
                  'darse cuenta': 'ê¹¨ë‹«ë‹¤, ì•Œì•„ì°¨ë¦¬ë‹¤',
                  'tener en cuenta': 'ê³ ë ¤í•˜ë‹¤, ì—¼ë‘ì— ë‘ë‹¤',
                  'por si acaso': 'í˜¹ì‹œ ëª¨ë¥´ë‹ˆê¹Œ',
                  'de vez en cuando': 'ê°€ë”',
                  'estar de acuerdo': 'ë™ì˜í•˜ë‹¤',
                  'tener razÃ³n': 'ì˜³ë‹¤, ë§ë‹¤',
                  'hacer falta': 'í•„ìš”í•˜ë‹¤',
                  'echar de menos': 'ê·¸ë¦¬ì›Œí•˜ë‹¤',
                  'llevarse bien': 'ì˜ ì§€ë‚´ë‹¤',
                  'ponerse en contacto': 'ì—°ë½í•˜ë‹¤',
                  'tomar el pelo': 'ë†€ë¦¬ë‹¤, ë†ë‹´í•˜ë‹¤',
                  'meter la pata': 'ì‹¤ìˆ˜í•˜ë‹¤',
                  'quedarse sin palabras': 'ë§ë¬¸ì´ ë§‰íˆë‹¤',
                  'estar hasta las narices': 'ì§€ê¸‹ì§€ê¸‹í•˜ë‹¤',
                  'dar igual': 'ìƒê´€ì—†ë‹¤',
                  'costar trabajo': 'í˜ë“¤ë‹¤',
                  'hacer gracia': 'ì¬ë¯¸ìˆë‹¤',
                  'dar la lata': 'ê·€ì°®ê²Œ í•˜ë‹¤',
                  'perder el tiempo': 'ì‹œê°„ì„ ë‚­ë¹„í•˜ë‹¤',
                  'tener suerte': 'ìš´ì´ ì¢‹ë‹¤',
                  'estar harto': 'ì§€ê¸‹ì§€ê¸‹í•˜ë‹¤',
                  'dar miedo': 'ë¬´ì„­ë‹¤',
                  'tener ganas': 'í•˜ê³  ì‹¶ë‹¤',
                  'hacer cola': 'ì¤„ì„ ì„œë‹¤',
                  'estar de moda': 'ìœ í–‰í•˜ë‹¤',
                  'salir adelante': 'ì•ìœ¼ë¡œ ë‚˜ì•„ê°€ë‹¤',
                  'llevarse un susto': 'ë†€ë¼ë‹¤',
                  'tener prisa': 'ê¸‰í•˜ë‹¤',
                  'hacer daÃ±o': 'í•´ë¥¼ ë¼ì¹˜ë‹¤',
                  'dar las gracias': 'ê°ì‚¬í•˜ë‹¤',
                  'tener cuidado': 'ì¡°ì‹¬í•˜ë‹¤',
                  'estar de broma': 'ë†ë‹´í•˜ë‹¤',
                  'dar pena': 'ì•ˆíƒ€ê¹ë‹¤',
                  'tener Ã©xito': 'ì„±ê³µí•˜ë‹¤',
                  'hacer el ridÃ­culo': 'ì›ƒìŒê±°ë¦¬ê°€ ë˜ë‹¤',
                  'dar vergÃ¼enza': 'ë¶€ë„ëŸ½ë‹¤',
                  'tener hambre': 'ë°°ê³ í”„ë‹¤',
                  'estar de viaje': 'ì—¬í–‰ ì¤‘ì´ë‹¤',
                  'dar la razÃ³n': 'ë™ì˜í•˜ë‹¤',
                  'tener sed': 'ëª©ë§ˆë¥´ë‹¤',
                  'estar de vuelta': 'ëŒì•„ì˜¤ë‹¤',
                  'tener frÃ­o': 'ì¶¥ë‹¤',
                  'estar de pie': 'ì„œ ìˆë‹¤',
                  'hacer ruido': 'ì†ŒìŒì„ ë‚´ë‹¤',
                  'dar calor': 'ë”°ëœ»í•˜ë‹¤',
                  'tener sueÃ±o': 'ì¡¸ë¦¬ë‹¤',
                  'estar de mal humor': 'ê¸°ë¶„ì´ ë‚˜ì˜ë‹¤',
                  'hacer ejercicio': 'ìš´ë™í•˜ë‹¤',
                  'dar asco': 'ì—­ê²¹ë‹¤',
                  
                  # ì—°ê²°ì–´ í‘œí˜„
                  'al fin y al cabo': 'ê²°êµ­',
                  'a fin de cuentas': 'ê²°êµ­',
                  'en resumidas cuentas': 'ìš”ì•½í•˜ë©´',
                  'por lo tanto': 'ë”°ë¼ì„œ',
                  'sin embargo': 'ê·¸ëŸ¬ë‚˜',
                  'por consiguiente': 'ê·¸ ê²°ê³¼',
                  'a pesar de': '~ì—ë„ ë¶ˆêµ¬í•˜ê³ ',
                  'con tal de que': '~í•˜ëŠ” í•œ',
                  'siempre y cuando': '~í•˜ëŠ” í•œ',
                  'a no ser que': '~í•˜ì§€ ì•ŠëŠ” í•œ',
                  'con el fin de': '~í•˜ê¸° ìœ„í•´',
                  'en cuanto a': '~ì— ê´€í•´ì„œ',
                  'en lo que respecta': '~ì— ê´€í•´ì„œ',
                  'por lo que respecta': '~ì— ê´€í•´ì„œ',
                  'en lo que se refiere': '~ì— ê´€í•´ì„œ',
                  'por otro lado': 'ë°˜ë©´ì—',
                  'de todos modos': 'ì–´ì¨Œë“ ',
                  'en cualquier caso': 'ì–´ë–¤ ê²½ìš°ë“ ',
                  'de todas formas': 'ì–´ì¨Œë“ ',
                  'en todo caso': 'ì–´ë–¤ ê²½ìš°ë“ ',
                  
                  # êµ¬ì–´ì²´ í‘œí˜„
                  'ponerse las pilas': 'ì •ì‹ ì°¨ë¦¬ë‹¤',
                  'tirar la casa por la ventana': 'ëˆì„ ë¬¼ ì“°ë“¯ í•˜ë‹¤',
                  'estar en las nubes': 'ë”´ ìƒê°ì— ë¹ ì ¸ìˆë‹¤',
                  'costar un ojo de la cara': 'ë§¤ìš° ë¹„ì‹¸ë‹¤',
                  'ser pan comido': 'ì‹ì€ ì£½ ë¨¹ê¸°ë‹¤',
                  'llover a cÃ¡ntaros': 'ë¹„ê°€ ì–µìˆ˜ë¡œ ë‚´ë¦¬ë‹¤',
                  'ser una ganga': 'ì‹¸ê²Œ ì‚¬ë‹¤',
                  'estar como una cabra': 'ë¯¸ì³¤ë‹¤',
                  'estar en babia': 'ë”´ ìƒê°ì— ë¹ ì ¸ìˆë‹¤',
                  'ser un hueso duro de roer': 'ë§Œë§Œì¹˜ ì•Šë‹¤',
                  
                  # ì •ì¹˜/ì‚¬íšŒ í‘œí˜„
                  'apoyar la propuesta': 'ì œì•ˆì„ ì§€ì§€í•˜ë‹¤',
                  'buscar un entendimiento': 'í•©ì˜ë¥¼ ì°¾ë‹¤',
                  'reflexionar sobre': '~ì— ëŒ€í•´ ìˆ™ê³ í•˜ë‹¤',
                  'desdeÃ±ar la oferta': 'ì œì•ˆì„ ë¬´ì‹œí•˜ë‹¤',
                  'abrir el diÃ¡logo': 'ëŒ€í™”ë¥¼ ì‹œì‘í•˜ë‹¤',
                  'tender puentes': 'ê°€êµë¥¼ ë†“ë‹¤',
                  'romper el consenso': 'í•©ì˜ë¥¼ ê¹¨ëœ¨ë¦¬ë‹¤',
                  'fortalecer la democracia': 'ë¯¼ì£¼ì£¼ì˜ë¥¼ ê°•í™”í•˜ë‹¤',
                  'garantizar la estabilidad': 'ì•ˆì •ì„ ë³´ì¥í•˜ë‹¤',
                  'promover el cambio': 'ë³€í™”ë¥¼ ì´‰ì§„í•˜ë‹¤',
                  
                  # ê²½ì œ/ê¸ˆìœµ í‘œí˜„
                  'productos financieros': 'ê¸ˆìœµ ìƒí’ˆ',
                  'preferentes': 'ìš°ì„ ì£¼',
                  'crisis econÃ³mica': 'ê²½ì œ ìœ„ê¸°',
                  'mercado financiero': 'ê¸ˆìœµ ì‹œì¥',
                  'inversiÃ³n segura': 'ì•ˆì „í•œ íˆ¬ì',
                  'riesgo elevado': 'ë†’ì€ ìœ„í—˜',
                  'rentabilidad': 'ìˆ˜ìµì„±',
                  'entidades bancarias': 'ì€í–‰ ê¸°ê´€',
                  'supervisiÃ³n financiera': 'ê¸ˆìœµ ê°ë…',
                  'protecciÃ³n al consumidor': 'ì†Œë¹„ì ë³´í˜¸'
              }
              
              # ì»¨í…ì¸ ì—ì„œ í‘œí˜„ ì°¾ê¸°
              found_expressions = []
              content_lower = content.lower()
              
              for expression, meaning in expression_dict.items():
                  if expression.lower() in content_lower:
                      found_expressions.append(f"{expression} ({meaning})")
              
              # ì¶”ê°€ì ìœ¼ë¡œ ë™ì‚¬ + ëª…ì‚¬ ì¡°í•©ì´ë‚˜ ì¤‘ìš”í•œ êµ¬ë¬¸ ì°¾ê¸°
              important_patterns = [
                  r'\b(se abre a \w+)\b',  # "se abre a reflexionar" ê°™ì€ íŒ¨í„´
                  r'\b(no buscar \w+)\b',   # "no buscar un entendimiento" ê°™ì€ íŒ¨í„´
                  r'\b(desdeÃ±ar \w+)\b',    # "desdeÃ±ar la oferta" ê°™ì€ íŒ¨í„´
                  r'\b(tender \w+)\b',      # "tender puentes" ê°™ì€ íŒ¨í„´
                  r'\b(fortalecer \w+)\b',  # "fortalecer la democracia" ê°™ì€ íŒ¨í„´
              ]
              
              for pattern in important_patterns:
                  matches = re.findall(pattern, content, re.IGNORECASE)
                  for match in matches:
                      if match not in [expr.split(' (')[0] for expr in found_expressions]:
                          # ê°„ë‹¨í•œ ë²ˆì—­ ì¶”ê°€
                          if 'se abre a' in match:
                              found_expressions.append(f"{match} (~ì— ì—´ë ¤ìˆë‹¤)")
                          elif 'no buscar' in match:
                              found_expressions.append(f"{match} (~ì„ ì°¾ì§€ ì•Šë‹¤)")
                          elif 'desdeÃ±ar' in match:
                              found_expressions.append(f"{match} (~ì„ ë¬´ì‹œí•˜ë‹¤)")
                          elif 'tender' in match:
                              found_expressions.append(f"{match} (~ì„ ë‚´ë°€ë‹¤)")
                          elif 'fortalecer' in match:
                              found_expressions.append(f"{match} (~ì„ ê°•í™”í•˜ë‹¤)")
              
              # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 2ê°œ ë°˜í™˜
              unique_expressions = list(dict.fromkeys(found_expressions))
              return unique_expressions[:2]

          def create_detailed_memo(content_type, data, weekday_name):
              if content_type == "article":
                  category = data.get('category', 'ì¼ë°˜')
                  expressions = data.get('expressions', [])
                  
                  expressions_text = ""
                  if expressions:
                      expr_list = ", ".join(expressions[:2])
                      expressions_text = f"ğŸ’¡ í•µì‹¬ í‘œí˜„: {expr_list} "
                  
                  return (f"ğŸ“° {category} ë¶„ì•¼ ê¸°ì‚¬ "
                         f"ğŸ“… ë°œí–‰: {data.get('published', 'ì˜¤ëŠ˜')} "
                         f"ğŸ¯ í•™ìŠµëª©í‘œ: 15ë¶„ ë…í•´, ì–´íœ˜ 5ê°œ ì •ë¦¬ "
                         f"{expressions_text}"
                         f"ğŸ“ ê¶Œì¥: ëª¨ë¥´ëŠ” ë‹¨ì–´ëŠ” ë…¸íŠ¸ì— ì •ë¦¬í•˜ë©° ì½ê¸°")

              elif content_type == "podcast":
                  podcast_name = data.get('podcast_name', '')
                  duration = data.get('duration', '15-25ë¶„')
                  topic = data.get('topic', 'ì¼ë°˜ ì£¼ì œ')
                  expressions = data.get('expressions', [])
                  episode_num = data.get('episode_number', '')
                  
                  # ì£¼ì œì— ë”°ë¥¸ í•™ìŠµëª©í‘œ ì„¤ì •
                  learning_goals = {
                      'ê²½ì œ': 'ê¸ˆìœµ ì–´íœ˜',
                      'ì •ì¹˜': 'ì •ì¹˜ ìš©ì–´',
                      'ë¬¸í™”': 'ë¬¸í™” í‘œí˜„',
                      'ì‚¬íšŒ': 'ì‚¬íšŒ ì´ìŠˆ ì–´íœ˜',
                      'êµìœ¡': 'êµìœ¡ ê´€ë ¨ ì–´íœ˜',
                      'ê±´ê°•': 'ì˜ë£Œ ìš©ì–´',
                      'ê¸°ìˆ ': 'ê¸°ìˆ  ìš©ì–´',
                      'ë¬¸ë²•': 'ë¬¸ë²• êµ¬ì¡°'
                  }
                  goal = learning_goals.get(topic, 'í•µì‹¬ ì–´íœ˜')
                  
                  # ì¬ìƒì‹œê°„ì— ë”°ë¥¸ ì²­ì·¨ ê³„íš ì„¤ì •
                  if ':' in duration:
                      try:
                          minutes, seconds = duration.split(':')
                          total_minutes = int(minutes)
                          if total_minutes > 30:
                              listen_plan = f"(30ë¶„ ì²­ì·¨ ëª©í‘œ)"
                          elif total_minutes > 20:
                              listen_plan = f"(ì „ì²´ {duration} ì²­ì·¨)"
                          else:
                              listen_plan = f"(ì „ì²´ {duration} ì²­ì·¨)"
                      except:
                          listen_plan = "(25ë¶„ ì²­ì·¨ ëª©í‘œ)"
                  else:
                      listen_plan = "(25ë¶„ ì²­ì·¨ ëª©í‘œ)"
                  
                  expressions_text = ""
                  if expressions:
                      # í‘œí˜„ë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ (í•œê¸€ ëœ» í¬í•¨)
                      expr_list = ", ".join(expressions[:2])
                      expressions_text = f"ğŸ’¡ í•µì‹¬ í‘œí˜„: {expr_list} "
                  
                  return (f"ğŸ§ {podcast_name} Ep.{episode_num} - {weekday_name} ìŠ¤í˜ì¸ íŒŸìºìŠ¤íŠ¸ "
                         f"â±ï¸ ì¬ìƒì‹œê°„: {duration} {listen_plan} "
                         f"ğŸ¯ í•™ìŠµëª©í‘œ: {goal} 5ê°œ ì •ë¦¬ "
                         f"ğŸŒ ì£¼ì œ: {topic} "
                         f"{expressions_text}"
                         f"ğŸ“ ê¶Œì¥: í•µì‹¬ ì–´íœ˜ì— ì§‘ì¤‘í•˜ì—¬ ì²­ì·¨")

          # ê¸°ì‚¬ ìˆ˜ì§‘
          reading_source = "${{ steps.phase.outputs.reading_source }}"
          article_data = None

          try:
              if reading_source == "20minutos":
                  feed_url = "https://www.20minutos.es/rss/"
              elif "El PaÃ­s" in reading_source:
                  if "ì‚¬ì„¤" in reading_source:
                      feed_url = "https://feeds.elpais.com/mrss-s/pages/ep/site/elpais.com/section/opinion"
                  else:
                      feed_url = "https://feeds.elpais.com/mrss-s/pages/ep/site/elpais.com/portada"
              
              feed = feedparser.parse(feed_url)
              if feed.entries:
                  latest = feed.entries[0]
                  summary = latest.get('summary', '')
                  # ì œëª© ì •ë¦¬ (escape sequence ì œê±°)
                  clean_title = latest.title.replace('&quot;', '"').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
                  # ê¸°ì‚¬ì—ì„œë„ í•µì‹¬ í‘œí˜„ ì¶”ì¶œ
                  expressions = get_key_expressions(clean_title, summary)
                  article_data = {
                      'title': clean_title,
                      'url': latest.link,
                      'published': latest.get('published', ''),
                      'category': extract_category_from_summary(summary),
                      'preview': summary,
                      'expressions': expressions
                  }
          except Exception as e:
              print(f"ê¸°ì‚¬ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")

          # íŒŸìºìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ìˆ˜ì§‘
          podcast_rss = "${{ steps.phase.outputs.podcast_rss }}"
          podcast_name = "${{ steps.phase.outputs.podcast_name }}"
          weekday_name = "${{ steps.phase.outputs.weekday_name }}"
          podcast_data = None

          try:
              feed = feedparser.parse(podcast_rss)
              if feed.entries:
                  latest = feed.entries[0]
                  episode_number = extract_episode_number(latest.title)
                  duration = extract_duration_from_feed(latest)
                  topic = extract_topic_keywords(latest.title, latest.get('summary', ''))
                  expressions = get_key_expressions(latest.title, latest.get('summary', ''))
                  
                  apple_base = "${{ steps.phase.outputs.podcast_apple_base }}"
                  episode_link = latest.link
                  
                  # Apple Podcasts ë§í¬ ìƒì„± ê°œì„ 
                  if 'npr.org' in episode_link or 'radioambulante' in episode_link:
                      # Radio Ambulanteì˜ ê²½ìš° ê¸°ë³¸ ë§í¬ ì‚¬ìš©
                      apple_episode_link = apple_base
                  else:
                      # ë‹¤ë¥¸ íŒŸìºìŠ¤íŠ¸ëŠ” ì—í”¼ì†Œë“œ ID ì¶”ì¶œ ì‹œë„
                      episode_id_match = re.search(r'/(\d+)', episode_link)
                      if episode_id_match:
                          apple_episode_link = f"{apple_base}?i={episode_id_match.group(1)}"
                      else:
                          apple_episode_link = apple_base
                  
                  # ì œëª© ì •ë¦¬ (escape sequence ì œê±°)
                  clean_title = latest.title.replace('&quot;', '"').replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
                  
                  podcast_data = {
                      'podcast_name': podcast_name,
                      'title': clean_title,
                      'url': apple_episode_link,
                      'original_url': episode_link,
                      'duration': duration,
                      'topic': topic,
                      'expressions': expressions,
                      'episode_number': episode_number or 'Latest',
                      'published': latest.get('published', ''),
                      'region': "${{ steps.phase.outputs.podcast_region }}"
                  }
          except Exception as e:
              print(f"íŒŸìºìŠ¤íŠ¸ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
              podcast_data = {
                  'podcast_name': podcast_name,
                  'title': f"{podcast_name} - ìµœì‹  ì—í”¼ì†Œë“œ",
                  'url': "${{ steps.phase.outputs.podcast_apple_base }}",
                  'duration': "15-25ë¶„",
                  'topic': "ì¼ë°˜ ì£¼ì œ",
                  'expressions': [],
                  'episode_number': 'Latest',
                  'region': "${{ steps.phase.outputs.podcast_region }}"
              }

          # ê²°ê³¼ ì¶œë ¥
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              if article_data:
                  # ë”°ì˜´í‘œì™€ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                  article_title_clean = article_data['title'].replace('\n', ' ').replace('\r', ' ').replace('"', '\\"').replace("'", "\\'")
                  article_memo_clean = create_detailed_memo('article', article_data, weekday_name)
                  f.write(f"article_title={article_title_clean}\n")
                  f.write(f"article_url={article_data['url']}\n")
                  f.write(f"article_memo={article_memo_clean}\n")
              
              if podcast_data:
                  # ë”°ì˜´í‘œì™€ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
                  podcast_title_clean = podcast_data['title'].replace('\n', ' ').replace('\r', ' ').replace('"', '\\"').replace("'", "\\'")
                  podcast_memo_clean = create_detailed_memo('podcast', podcast_data, weekday_name)
                  f.write(f"podcast_title={podcast_title_clean}\n")
                  f.write(f"podcast_url={podcast_data['url']}\n")
                  f.write(f"podcast_memo={podcast_memo_clean}\n")
                  f.write(f"episode_number={podcast_data['episode_number']}\n")
          EOF

      - name: Add materials to Notion with detailed information
        run: |
          python3 << 'EOF'
          import os
          import requests
          import json
          from datetime import datetime

          notion_token = os.environ['NOTION_TOKEN']
          database_id = os.environ['NOTION_DATABASE_ID']

          headers = {
              "Authorization": f"Bearer {notion_token}",
              "Notion-Version": "2022-06-28", 
              "Content-Type": "application/json"
          }

          today = "${{ steps.phase.outputs.date }}"

          # ë…í•´ ìë£Œ ì¶”ê°€
          article_title = "${{ steps.materials.outputs.article_title }}"
          article_url = "${{ steps.materials.outputs.article_url }}"
          article_memo = "${{ steps.materials.outputs.article_memo }}"

          if article_title and article_url:
              reading_payload = {
                  "parent": {"database_id": database_id},
                  "properties": {
                      "ë‚´ìš©": {"title": [{"text": {"content": f"[{today}] {article_title}"}}]},
                      "URL": {"url": article_url},
                      "ë‚ ì§œ": {"date": {"start": today}},
                      "ì§€ì—­": {"select": {"name": "ìŠ¤í˜ì¸"}},
                      "ë‚œì´ë„": {"select": {"name": "${{ steps.phase.outputs.reading_difficulty }}"}},
                      "ìë£Œ ìœ í˜•": {"select": {"name": "ê¸°ì‚¬/ë‰´ìŠ¤"}},
                      "í•™ìŠµ ì˜ì—­": {"select": {"name": "ë…í•´"}},
                      "ë©”ëª¨": {"rich_text": [{"text": {"content": article_memo}}]}
                  }
              }
              
              try:
                  response = requests.post(
                      "https://api.notion.com/v1/pages",
                      headers=headers,
                      json=reading_payload
                  )
                  if response.status_code == 200:
                      print(f"âœ… ë…í•´ ìë£Œ ì¶”ê°€ ì„±ê³µ: {article_title}")
                  else:
                      print(f"âŒ ë…í•´ ìë£Œ ì¶”ê°€ ì‹¤íŒ¨: {response.text}")
              except Exception as e:
                  print(f"ë…í•´ ìë£Œ ì „ì†¡ ì˜¤ë¥˜: {e}")

          # ì²­í•´ ìë£Œ ì¶”ê°€
          podcast_title = "${{ steps.materials.outputs.podcast_title }}"
          podcast_url = "${{ steps.materials.outputs.podcast_url }}"
          podcast_memo = "${{ steps.materials.outputs.podcast_memo }}"
          episode_number = "${{ steps.materials.outputs.episode_number }}"

          display_title = f"${{ steps.phase.outputs.podcast_name }} Ep.{episode_number}"

          podcast_payload = {
              "parent": {"database_id": database_id},
              "properties": {
                  "ë‚´ìš©": {"title": [{"text": {"content": f"[{today}] {display_title}"}}]},
                  "URL": {"url": podcast_url},
                  "ë‚ ì§œ": {"date": {"start": today}},
                  "ì§€ì—­": {"select": {"name": "${{ steps.phase.outputs.podcast_region }}"}},
                  "ë‚œì´ë„": {"select": {"name": "C1"}},
                  "ìë£Œ ìœ í˜•": {"select": {"name": "íŒŸìºìŠ¤íŠ¸"}},
                  "í•™ìŠµ ì˜ì—­": {"select": {"name": "ì²­í•´"}},
                  "ë©”ëª¨": {"rich_text": [{"text": {"content": podcast_memo}}]}
              }
          }

          try:
              response = requests.post(
                  "https://api.notion.com/v1/pages",
                  headers=headers,
                  json=podcast_payload
              )
              if response.status_code == 200:
                  print(f"âœ… ì²­í•´ ìë£Œ ì¶”ê°€ ì„±ê³µ: {display_title}")
              else:
                  print(f"âŒ ì²­í•´ ìë£Œ ì¶”ê°€ ì‹¤íŒ¨: {response.text}")
          except Exception as e:
              print(f"ì²­í•´ ìë£Œ ì „ì†¡ ì˜¤ë¥˜: {e}")
          EOF

      - name: Send detailed notification
        if: success()
        run: |
          echo "ğŸ‰ ${{ steps.phase.outputs.date }} (${{ steps.phase.outputs.weekday_name }}) ìŠ¤í˜ì¸ì–´ í•™ìŠµ ìë£Œ ìë™ ìˆ˜ì§‘ ì™„ë£Œ!"
          echo ""
          echo "ğŸ“– ë…í•´ ìë£Œ:"
          echo "   ì œëª©: ${{ steps.materials.outputs.article_title }}"
          echo "   ì¶œì²˜: ${{ steps.phase.outputs.reading_source }}"
          echo "   ë‚œì´ë„: ${{ steps.phase.outputs.reading_difficulty }}"
          echo ""
          echo "ğŸ§ ì²­í•´ ìë£Œ:"
          echo "   ì œëª©: ${{ steps.phase.outputs.podcast_name }} Ep.${{ steps.materials.outputs.episode_number }}"
          echo "   ì§€ì—­: ${{ steps.phase.outputs.podcast_region }}"
          echo "   ë§í¬: Apple Podcasts ì•±ì—ì„œ ì¬ìƒ ê°€ëŠ¥"
          echo ""
          echo "ğŸ“… í•™ìŠµ ì£¼ì°¨: ${{ steps.phase.outputs.week_num }}ì£¼ì°¨"
          echo "ğŸ’¡ íŒ: íŒŸìºìŠ¤íŠ¸ëŠ” Apple Podcasts ì•±ì„ í†µí•´ ì ‘ì†í•˜ì‹œë©´ ì›í™œí•˜ê²Œ ì¬ìƒë©ë‹ˆë‹¤!"
