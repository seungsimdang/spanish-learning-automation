#!/usr/bin/env python3
"""
LLM-based Spanish content analyzer using ChatGPT API.
ChatGPT APIÎ•º ÏÇ¨Ïö©Ìïú Ïä§ÌéòÏù∏Ïñ¥ ÏΩòÌÖêÏ∏† Î∂ÑÏÑùÍ∏∞
"""

import os
import json
import requests
import time
from typing import List, Dict, Optional

class SpanishLLMAnalyzer:
    def __init__(self, api_key: Optional[str] = None):
        """
        Initialize the LLM analyzer with ChatGPT API
        """
        self.api_key = api_key or os.environ.get('OPENAI_API_KEY')
        if not self.api_key:
            raise ValueError("OpenAI API key is required. Set OPENAI_API_KEY environment variable.")
        
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
    
    def _make_api_call(self, prompt: str, max_tokens: int = 800) -> str:
        """
        Make API call to ChatGPT
        """
        try:
            payload = {
                "model": "gpt-4o-mini",  # ÎπÑÏö© Ìö®Ïú®Ï†ÅÏù∏ Î™®Îç∏ ÏÇ¨Ïö©
                "messages": [
                    {
                        "role": "system",
                        "content": "You are an expert Spanish language teacher and linguist specializing in analyzing Spanish content for language learners."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "max_tokens": max_tokens,
                "temperature": 0.3,  # ÏùºÍ¥ÄÏÑ± ÏûàÎäî Î∂ÑÏÑùÏùÑ ÏúÑÌï¥ ÎÇÆÏùÄ temperature
                "top_p": 0.9
            }
            
            response = requests.post(self.base_url, headers=self.headers, json=payload, timeout=30)
            response.raise_for_status()
            
            result = response.json()
            return result['choices'][0]['message']['content'].strip()
            
        except requests.exceptions.RequestException as e:
            print(f"API Ìò∏Ï∂ú Ïò§Î•ò: {e}")
            return ""
        except Exception as e:
            print(f"Î∂ÑÏÑù Ïò§Î•ò: {e}")
            return ""
    
    def analyze_podcast_colloquialisms(self, transcript: str, difficulty: str = "B2") -> List[str]:
        """
        Extract colloquial expressions from podcast transcript using LLM
        ÌåüÏ∫êÏä§Ìä∏ transcriptÏóêÏÑú Íµ¨Ïñ¥Ï≤¥ ÌëúÌòÑ Ï∂îÏ∂ú
        """
        if not transcript:
            return []
        
        # ÌÖçÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ Í∏∏Î©¥ Ï≤òÏùå 2000ÏûêÎßå ÏÇ¨Ïö©
        if len(transcript) > 2000:
            transcript = transcript[:2000] + "..."
        
        prompt = f"""
You are analyzing Spanish text to find ACTUAL colloquial expressions that appear in the text.

CRITICAL RULE: Only extract expressions that are ACTUALLY PRESENT in the provided text. Do not suggest or create expressions that are not in the text.

Text to analyze:
{transcript}

Instructions:
1. Read the text carefully
2. Look for actual colloquial expressions, informal phrases, or conversational elements that appear in the text
3. If the text is formal and contains no colloquial expressions, return "NO_COLLOQUIAL_EXPRESSIONS_FOUND"
4. If you find expressions, format them as: "expression" ‚Üí Korean translation (usage context)

Examples of what to look for (ONLY if they actually appear in the text):
- Conversational fillers: o sea, bueno, pues, entonces
- Question tags: ¬øverdad?, ¬øno?, ¬øsabes?
- Informal transitions: por cierto, a prop√≥sito, adem√°s
- Opinion expressions: me parece que, creo que, la cosa es que

Response format (only if expressions are found in the text):
- "actual_expression_from_text" ‚Üí Korean meaning (context)

If no colloquial expressions are found in this formal text, respond with: NO_COLLOQUIAL_EXPRESSIONS_FOUND
"""
        
        response = self._make_api_call(prompt, max_tokens=400)
        
        if not response:
            return []
        
        # "NO_COLLOQUIAL_EXPRESSIONS_FOUND" ÏùëÎãµ Ï≤òÎ¶¨
        if "NO_COLLOQUIAL_EXPRESSIONS_FOUND" in response:
            print(f"    üìù LLM Î∂ÑÏÑù Í≤∞Í≥º: ÌÖçÏä§Ìä∏Ïóê Íµ¨Ïñ¥Ï≤¥ ÌëúÌòÑÏù¥ ÏóÜÏùå")
            return []
        
        # ÏùëÎãµÏóêÏÑú ÌëúÌòÑÎì§ Ï∂îÏ∂ú
        expressions = []
        lines = response.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('-') and '"' in line and '‚Üí' in line:
                try:
                    # "- "expression" ‚Üí meaning (context)" ÌòïÏãù ÌååÏã±
                    start_quote = line.find('"')
                    end_quote = line.find('"', start_quote + 1)
                    if start_quote != -1 and end_quote != -1:
                        expression = line[start_quote+1:end_quote]
                        remaining = line[end_quote+1:]
                        if '‚Üí' in remaining:
                            meaning_part = remaining.split('‚Üí')[1].strip()
                            # (usage context) Î∂ÄÎ∂Ñ Ï†úÍ±∞
                            if '(' in meaning_part:
                                meaning = meaning_part.split('(')[0].strip()
                            else:
                                meaning = meaning_part.strip()
                            expressions.append(f"{expression} ({meaning})")
                except Exception as e:
                    print(f"Íµ¨Ïñ¥Ï≤¥ ÌëúÌòÑ ÌååÏã± Ïò§Î•ò: {e}")
                    continue
        
        return expressions[:5]  # ÏµúÎåÄ 5Í∞ú Î∞òÌôò
    
    def analyze_article_grammar(self, article_content: str, difficulty: str = "B2") -> List[str]:
        """
        Analyze grammar structures in article content using LLM
        Í∏∞ÏÇ¨ ÎÇ¥Ïö©Ïùò Î¨∏Î≤ï Íµ¨Ï°∞ Î∂ÑÏÑù
        """
        if not article_content:
            return []
        
        # ÌÖçÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ Í∏∏Î©¥ Ï≤òÏùå 1500ÏûêÎßå ÏÇ¨Ïö©
        if len(article_content) > 1500:
            article_content = article_content[:1500] + "..."
        
        prompt = f"""
Analyze this Spanish article and identify 3-4 specific grammar structures suitable for {difficulty} level learners.

For each grammar point, provide:
1. The exact sentence from the text where it appears
2. The specific grammar structure used in Korean
3. The CEFR level of that structure
4. A brief explanation in Korean

Article content:
{article_content}

Please provide exactly 3-4 grammar points in this format:
- Î¨∏Ïû•: "exact sentence from text"
- Î¨∏Î≤ï: Korean grammar term
- Î†àÎ≤®: CEFR level (A1, A2, B1, B2, C1, C2)
- ÏÑ§Î™Ö: Brief Korean explanation

Example format:
- Î¨∏Ïû•: "Si hubiera tenido m√°s tiempo, habr√≠a terminado el proyecto."
- Î¨∏Î≤ï: Ï†ëÏÜçÎ≤ï Í≥ºÍ±∞ÏôÑÎ£å
- Î†àÎ≤®: C1
- ÏÑ§Î™Ö: Í≥ºÍ±∞Ïùò ÎπÑÌòÑÏã§Ï†Å ÏÉÅÌô©Í≥º Í∑∏ Í≤∞Í≥ºÎ•º ÌëúÌòÑÌïòÎäî Íµ¨Ï°∞

Focus on grammar structures appropriate for {difficulty} level such as:
- B1: ÌòÑÏû¨/Í≥ºÍ±∞ ÏãúÏ†ú, ser vs estar, Ïû¨Í∑ÄÎèôÏÇ¨
- B2: Ï†ëÏÜçÎ≤ï ÌòÑÏû¨/Í≥ºÍ±∞, Ï°∞Í±¥Î≤ï, ÏôÑÎ£å ÏãúÏ†ú
- C1: Ï†ëÏÜçÎ≤ï ÏôÑÎ£å, Î≥µÌï© Ï°∞Í±¥Î¨∏, ÏàòÎèôÌÉú

Return only the grammar points in the exact format above, no additional text.
"""
        
        response = self._make_api_call(prompt, max_tokens=600)
        
        if not response:
            return []
        
        # ÏùëÎãµÏóêÏÑú Î¨∏Î≤ï Ìè¨Ïù∏Ìä∏Îì§ Ï∂îÏ∂úÌïòÍ≥† ÏÉàÎ°úÏö¥ ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò
        grammar_points = []
        lines = response.split('\n')
        
        current_point = {}
        for line in lines:
            line = line.strip()
            if line.startswith('- Î¨∏Ïû•:'):
                if current_point:  # Ïù¥Ï†Ñ Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•
                    if all(key in current_point for key in ['Î¨∏Ïû•', 'Î¨∏Î≤ï', 'Î†àÎ≤®']):
                        # ÏÉàÎ°úÏö¥ ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò: "Ïù¥ Î¨∏Ïû•ÏóêÎäî Ï†ëÏÜçÎ≤ï Í≥ºÍ±∞Í∞Ä Ïì∞Ïù¥Í≥† ÏûàÎã§ (B2): 'Î¨∏Ïû•' - ÏÑ§Î™Ö"
                        sentence = current_point['Î¨∏Ïû•']
                        grammar = current_point['Î¨∏Î≤ï']
                        level = current_point['Î†àÎ≤®']
                        explanation = current_point.get('ÏÑ§Î™Ö', '')
                        
                        if len(sentence) > 80:
                            sentence = sentence[:80] + "..."
                        
                        point_text = f"Ïù¥ Î¨∏Ïû•ÏóêÎäî {grammar}Í∞Ä Ïì∞Ïù¥Í≥† ÏûàÎã§ ({level}): '{sentence}'"
                        if explanation:
                            point_text += f" - {explanation}"
                        
                        grammar_points.append(point_text)
                current_point = {'Î¨∏Ïû•': line[6:].strip().strip('"')}
            elif line.startswith('- Î¨∏Î≤ï:'):
                current_point['Î¨∏Î≤ï'] = line[6:].strip()
            elif line.startswith('- Î†àÎ≤®:'):
                current_point['Î†àÎ≤®'] = line[6:].strip()
            elif line.startswith('- ÏÑ§Î™Ö:'):
                current_point['ÏÑ§Î™Ö'] = line[6:].strip()
        
        # ÎßàÏßÄÎßâ Ìè¨Ïù∏Ìä∏ Ï†ÄÏû•
        if current_point and all(key in current_point for key in ['Î¨∏Ïû•', 'Î¨∏Î≤ï', 'Î†àÎ≤®']):
            sentence = current_point['Î¨∏Ïû•']
            grammar = current_point['Î¨∏Î≤ï']
            level = current_point['Î†àÎ≤®']
            explanation = current_point.get('ÏÑ§Î™Ö', '')
            
            if len(sentence) > 80:
                sentence = sentence[:80] + "..."
            
            point_text = f"Ïù¥ Î¨∏Ïû•ÏóêÎäî {grammar}Í∞Ä Ïì∞Ïù¥Í≥† ÏûàÎã§ ({level}): '{sentence}'"
            if explanation:
                point_text += f" - {explanation}"
            
            grammar_points.append(point_text)
        
        return grammar_points[:4]  # ÏµúÎåÄ 4Í∞ú Î∞òÌôò
    
    def analyze_text_difficulty(self, content: str) -> str:
        """
        Analyze text difficulty using LLM
        LLMÏùÑ ÏÇ¨Ïö©Ìïú ÌÖçÏä§Ìä∏ ÎÇúÏù¥ÎèÑ Î∂ÑÏÑù
        """
        if not content:
            return "B2"
        
        # ÌÖçÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ Í∏∏Î©¥ Ï≤òÏùå 1000ÏûêÎßå ÏÇ¨Ïö©
        if len(content) > 1000:
            content = content[:1000] + "..."
        
        prompt = f"""
Analyze this Spanish text and determine its CEFR difficulty level (A1, A2, B1, B1+, B2, B2+, C1, C2).

Consider:
- Vocabulary complexity
- Grammar structures used
- Sentence length and complexity
- Abstract vs concrete concepts
- Technical vs everyday language

Text:
{content}

Respond with only the CEFR level (e.g., "B2" or "B2+" or "C1"), no additional text.
"""
        
        response = self._make_api_call(prompt, max_tokens=50)
        
        # ÏùëÎãµÏóêÏÑú Î†àÎ≤® Ï∂îÏ∂ú
        if response:
            response = response.strip().upper()
            valid_levels = ['A1', 'A2', 'B1', 'B1+', 'B2', 'B2+', 'C1', 'C2']
            for level in valid_levels:
                if level in response:
                    return level
        
        return "B2"  # Í∏∞Î≥∏Í∞í